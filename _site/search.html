<!DOCTYPE html>
<html lang="en">
  

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Search the site</title>
  <meta name="description" content="        ">

  <link rel="canonical" href="http://0.0.0.0:4000/textbook/search">
  <link rel="alternate" type="application/rss+xml" title="Stat 88 Textbook" href="http://0.0.0.0:4000/textbook/feed.xml">

  <meta property="og:url"         content="http://0.0.0.0:4000/textbook/search" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Search the site" />
<meta property="og:description" content="        " />
<meta property="og:image"       content="http://0.0.0.0:4000/textbook/images/stat88_logo.png" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "http://0.0.0.0:4000/textbook/search",
  "headline": "Search the site",
  "datePublished": "2019-11-01T10:32:33-05:00",
  "dateModified": "2019-11-01T10:32:33-05:00",
  "description": "        ",
  "author": {
    "@type": "Person",
    "name": "Ani Adhikari"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "http://0.0.0.0:4000/textbook",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "http://0.0.0.0:4000/textbook",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/textbook/assets/css/styles.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css ">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/textbook/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    }
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>

  <!-- DOM updating function -->
  <script>
const runWhenDOMLoaded = cb => {
  if (document.readyState != 'loading') {
    cb()
  } else if (document.addEventListener) {
    document.addEventListener('DOMContentLoaded', cb)
  } else {
    document.attachEvent('onreadystatechange', function() {
      if (document.readyState == 'complete') cb()
    })
  }
}

// Helper function to init things quickly
initFunction = function(myfunc) {
  runWhenDOMLoaded(myfunc);
  document.addEventListener('turbolinks:load', myfunc);
};
</script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/textbook';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script>
const initAnchors = () => {
  if (window.anchors === undefined) {
    setTimeout(initAnchors, 250)
    return
  }
  anchors.add("main h1, main h2, main h3, main h4")
}

initFunction(initAnchors);
</script>


  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Selectors for elements on the page -->
  <script>
/**
 * Select various elements on the page for later use
 */

// IDs we'll attach to cells
const codeCellId = index => `codecell${index}`
const inputCellId = index => `inputcell${index}`

pageElements = {}

// All code cells
findCodeCells = function() {
    var codeCells = document.querySelectorAll('div.c-textbook__content > div.highlighter-rouge > div.highlight > pre, div.input_area pre, div.text_cell_render div.highlight pre')
    pageElements['codeCells'] = codeCells;

    codeCells.forEach((codeCell, index) => {
      const id = codeCellId(index)
      codeCell.setAttribute('id', id)
    })
};

initFunction(findCodeCells);

// All cells in general
findInputCells = function() {
    var inputCells = document.querySelectorAll('div.jb_cell')
    pageElements['inputCells'] = inputCells;

    inputCells.forEach((inputCell, index) => {
        const id = inputCellId(index)
        inputCell.setAttribute('id', id)
    })
};

initFunction(findInputCells);
</script>

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->



  <!-- Load the auto-generating TOC -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js" async></script>
<script>
const initToc = () => {
  if (window.tocbot === undefined) {
    setTimeout(initToc, 250)
    return
  }

  // Check whether we have any sidebar content. If not, then show the sidebar earlier.
  var SIDEBAR_CONTENT_TAGS = ['.tag_full_width', '.tag_popout'];
  var sidebar_content_query = SIDEBAR_CONTENT_TAGS.join(', ')
  if (document.querySelectorAll(sidebar_content_query).length === 0) {
    document.querySelector('nav.onthispage').classList.add('no_sidebar_content')
  }

  // Initialize the TOC bot
  tocbot.init({
    tocSelector: 'nav.onthispage',
    contentSelector: '.c-textbook__content',
    headingSelector: 'h2, h3',
    orderedList: false,
    collapseDepth: 6,
    listClass: 'toc__menu',
    activeListItemClass: "",  // Not using
    activeLinkClass: "", // Not using
  });

}
initFunction(initToc);
</script>


  <!-- Google analytics -->
  <script src="/textbook/assets/js/ga.js" async></script>

  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/textbook/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/textbook/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/textbook/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  

  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script>
/**
 * Set up copy/paste for code blocks
 */
const clipboardButton = id =>
  `<a id="copy-button-${id}" class="btn copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#${id}">
    <img src="/textbook/assets/images/copy-button.svg" alt="Copy to clipboard">
  </a>`

// Clears selected text since ClipboardJS will select the text when copying
const clearSelection = () => {
  if (window.getSelection) {
    window.getSelection().removeAllRanges()
  } else if (document.selection) {
    document.selection.empty()
  }
}

// Changes tooltip text for two seconds, then changes it back
const temporarilyChangeTooltip = (el, newText) => {
  const oldText = el.getAttribute('data-tooltip')
  el.setAttribute('data-tooltip', newText)
  setTimeout(() => el.setAttribute('data-tooltip', oldText), 2000)
}

const addCopyButtonToCodeCells = () => {
  // If ClipboardJS hasn't loaded, wait a bit and try again. This
  // happens because we load ClipboardJS asynchronously.
  if (window.ClipboardJS === undefined) {
    setTimeout(addCopyButtonToCodeCells, 250)
    return
  }

  pageElements['codeCells'].forEach((codeCell) => {
    const id = codeCell.getAttribute('id')
    if (document.getElementById("copy-button" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', clipboardButton(id));
    }
  })

  const clipboard = new ClipboardJS('.copybtn')
  clipboard.on('success', event => {
    clearSelection()
    temporarilyChangeTooltip(event.trigger, 'Copied!')
  })

  clipboard.on('error', event => {
    temporarilyChangeTooltip(event.trigger, 'Failed to copy')
  })

  // Get rid of clipboard before the next page visit to avoid memory leak
  document.addEventListener('turbolinks:before-visit', () =>
    clipboard.destroy()
  )
}

initFunction(addCopyButtonToCodeCells);
</script>


  <!-- Hide cell code -->
  <script>
    /**
    Add buttons to hide code cells
    */


    var setCodeCellVisibility = function (inputField, kind) {
        // Update the image and class for hidden
        var id = inputField.getAttribute('data-id');
        var codeCell = document.querySelector(`#${id} div.highlight`);

        if (kind === "visible") {
            codeCell.classList.remove('hidden');
            inputField.checked = true;
        } else {
            codeCell.classList.add('hidden');
            inputField.checked = false;
        }
    }

    var toggleCodeCellVisibility = function (event) {
        // The label is clicked, and now we decide what to do based on the input field's clicked status
        if (event.target.tagName === "LABEL") {
            var inputField = event.target.previousElementSibling;
        } else {
            // It is the span inside the target
            var inputField = event.target.parentElement.previousElementSibling;
        }

        if (inputField.checked === true) {
            setCodeCellVisibility(inputField, "visible");
        } else {
            setCodeCellVisibility(inputField, "hidden");
        }
    }


    // Button constructor
    const hideCodeButton = id => `<input class="hidebtn" type="checkbox" id="hidebtn${id}" data-id="${id}"><label title="Toggle cell" for="hidebtn${id}" class="plusminus"><span class="pm_h"></span><span class="pm_v"></span></label>`

    var addHideButton = function () {
        // If a hide button is already added, don't add another
        if (document.querySelector('div.tag_hide_input input') !== null) {
            return;
        }

        // Find the input cells and add a hide button
        pageElements['inputCells'].forEach(function (inputCell) {
            if (!inputCell.classList.contains("tag_hide_input")) {
                // Skip the cell if it doesn't have a hidecode class
                return;
            }

            const id = inputCell.getAttribute('id')

            // Insert the button just inside the end of the next div
            inputCell.querySelector('div.input').insertAdjacentHTML('beforeend', hideCodeButton(id))

            // Set up the visibility toggle
            hideLink = document.querySelector(`#${id} div.inner_cell + input + label`);
            hideLink.addEventListener('click', toggleCodeCellVisibility)
        });
    }


    // Initialize the hide buttos
    var initHiddenCells = function () {
        // Add hide buttons to the cells
        addHideButton();

        // Toggle the code cells that should be hidden
        document.querySelectorAll('div.tag_hide_input input').forEach(function (item) {
            setCodeCellVisibility(item, 'hidden');
            item.checked = true;
        })
    }

    initFunction(initHiddenCells);

</script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });
    
    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/textbook/assets/css/styles.css",
        style: "#textbook_content {padding-top: 40px};",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList,
        documentTitle: "This a section from 'Theory Meets Data' by Ani Adhikari; This book is licensed for free consumption under the following license: (CC BY-NC-ND 4.0)"
    })
};
initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}
initFunction(initPrint)
</script>
© 2019 GitHub, Inc.
</head>

  <body>
    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://stat88.github.io/"><img src="/textbook/images/stat88_logo.png" class="textbook_logo" id="sidebar-logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">Stat 88 Textbook</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="http://stat88.org/"
        >
          
          Course Home
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/intro.html"
        >
          
          Authors and License
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href=".html"
        >
          
          Search
        </a>

        
      </li>

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/Chapter_01/00_The_Basics.html"
        >
          
            1.
          
          The Basics
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_01/01_Probabilities_as_Proportions.html"
                >
                  
                    1.1
                  
                  Probabilities as Proportions
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_01/02_Exact_Calculation_or_Bound.html"
                >
                  
                    1.2
                  
                  Exact Calculation or Bound
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_01/03_Fundamental_Rules.html"
                >
                  
                    1.3
                  
                  Fundamental Rules
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_01/04_Exercises.html"
                >
                  
                    1.4
                  
                  Exercises
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/Chapter_02/00_Intersections_and_Conditioning.html"
        >
          
            2.
          
          Intersections and Conditioning
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_02/01_The_Chance_of_an_Intersection.html"
                >
                  
                    2.1
                  
                  The Chance of an Intersection
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html"
                >
                  
                    2.2
                  
                  Symmetry in Simple Random Sampling
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_02/03_Bayes_Rule.html"
                >
                  
                    2.3
                  
                  Bayes' Rule
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_02/04_Use_and_Interpretation.html"
                >
                  
                    2.4
                  
                  Use and Interpretation
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_02/05_Independence.html"
                >
                  
                    2.5
                  
                  Independence
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_02/06_Exercises.html"
                >
                  
                    2.6
                  
                  Exercises
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/Chapter_03/00_Random_Counts.html"
        >
          
            3.
          
          Random Counts
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_03/01_Success_and_Failure.html"
                >
                  
                    3.1
                  
                  Success and Failure
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_03/02_Random_Variables.html"
                >
                  
                    3.2
                  
                  Random Variables
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_03/03_The_Binomial_Distribution.html"
                >
                  
                    3.3
                  
                  The Binomial Distribution
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_03/04_The_Hypergeometric_Distribution.html"
                >
                  
                    3.4
                  
                  The Hypergeometric Distribution
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_03/05_Examples.html"
                >
                  
                    3.5
                  
                  Examples
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_03/06_Exercises.html"
                >
                  
                    3.6
                  
                  Exercises
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/Chapter_04/00_Infinitely_Many_Values.html"
        >
          
            4.
          
          Infinitely Many Values
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_04/01_Cumulative_Distribution_Function.html"
                >
                  
                    4.1
                  
                  Cumulative Distribution Function (CDF)
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_04/02_Waiting_Times.html"
                >
                  
                    4.2
                  
                  Waiting Times
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_04/03_Exponential_Approximations.html"
                >
                  
                    4.3
                  
                  Exponential Approximations
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_04/04_The_Poisson_Distribution.html"
                >
                  
                    4.4
                  
                  The Poisson Distribution
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_04/05_Exercises.html"
                >
                  
                    4.5
                  
                  Exercises
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/Chapter_05/00_Expectation.html"
        >
          
            5.
          
          Expectation
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_05/01_Definition.html"
                >
                  
                    5.1
                  
                  Definition
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_05/02_Functions_of_Random_Variables.html"
                >
                  
                    5.2
                  
                  Functions of Random Variables
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_05/03_Method_of_Indicators.html"
                >
                  
                    5.3
                  
                  Method of Indicators
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_05/04_Unbiased_Estimators.html"
                >
                  
                    5.4
                  
                  Unbiased Estimators
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_05/05_Conditional_Expectation.html"
                >
                  
                    5.5
                  
                  Conditional Expectation
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_05/06_Expectation_by_Conditioning.html"
                >
                  
                    5.6
                  
                  Expectation by Conditioning
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_05/07_Exercises.html"
                >
                  
                    5.7
                  
                  Exercises
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/Chapter_06/00_Measuring_Variability.html"
        >
          
            6.
          
          Measuring Variability
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_06/01_Variance_and_Standard_Deviation.html"
                >
                  
                    6.1
                  
                  Variance and Standard_Deviation
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_06/02_Simplifying_the_Calculation.html"
                >
                  
                    6.2
                  
                  Simplifying the Calculation
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_06/03_Markovs_Inequality.html"
                >
                  
                    6.3
                  
                  Markov's Inequality
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_06/04_Chebyshevs_Inequality.html"
                >
                  
                    6.4
                  
                  Chebyshev's Inequality
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_06/05_Exercises.html"
                >
                  
                    6.5
                  
                  Exercises
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/Chapter_07/00_The_Variance_of_a_Sum.html"
        >
          
            7.
          
          The Variance of a Sum
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_07/01_Sums_of_Independent_Random_Variables.html"
                >
                  
                    7.1
                  
                  Sums of Independent Random Variables
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_07/02_Sampling_Without_Replacement.html"
                >
                  
                    7.2
                  
                  Sampling Without Replacement
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_07/03_The_Law_of_Averages.html"
                >
                  
                    7.3
                  
                  The Law of Averages
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_07/04_Exercises.html"
                >
                  
                    7.4
                  
                  Exercises
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/notebooks/Chapter_08/00_Central_Limit_Theorem.html"
        >
          
            8.
          
          The Central Limit Theorem
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_08/01_Distribution_of_a_Sample_Sum.html"
                >
                  
                    8.1
                  
                  Distribution of a Sample Sum
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_08/02_Standard_Normal_Curve.html"
                >
                  
                    8.2
                  
                  Standard Normal Curve
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_08/03_Normal_Approximation.html"
                >
                  
                    8.3
                  
                  Normal Approximation
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/notebooks/Chapter_08/04_How_Large_is_Large.html"
                >
                  
                    8.4
                  
                  How Large is Large
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><i class="fa fa-list"></i>   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/textbook/search.html" class="topbar-right-button" id="search-button"><i class="fa fa-search"></i></a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
              <div class="search-content__inner-wrap">
    <input type="text" id="lunr_search" class="search-input" tabindex="-1" placeholder="'Enter your search term...''" />
    <div id="results" class="results"></div>
</div>

<script>
    // Add the lunr store since we will now search it
    var store = [{
        "title": "The Basics",
        
        "excerpt":
            "The Basics This chapter sets out the rules of the game – the axioms on which the theory of probability is based. The axioms aren't laws of nature. They are minimal conditions outlined by probabilists to reflect some reasonable requirements about how probabilities should behave. It turns out that the simple set of axioms leads to a powerful theory that has an extraordinary range of application, some of which we will study in this course. We will start out by examining our own intuition about probabilities as proportions, and then look at some ways in which proportions behave. This will...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_01/00_The_Basics.html",
        "teaser":null},{
        "title": "Probabilities as Proportions",
        
        "excerpt":
            "Probabilities as Proportions You can think of probability as a numerical measure of uncertainty. Exactly what this means is the subject of considerable philosophical debate which we will touch on from time to time. For now, it is reassuring to note that almost all sides in the debate agree on some basic computational principles. Indeed, these principles have been known to gamblers through the ages. To state the principles it helps to have some terminology and notation. In this section we'll just set these up informally and get a taste of some of the considerations that are involved in calculating...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_01/01_Probabilities_as_Proportions.html",
        "teaser":null},{
        "title": "Exact Calculation or Bound",
        
        "excerpt":
            "Exact Calculation, or Bound? All of the questions we asked in the previous section could be answered based on the information given. But sometimes the information at hand is not enough for us to be able to find the probability of an event of interest. Let's look at an example of this and then see if there is anything useful we can say in situations where we can't find an answer exactly. As a reminder, here is the Pew Research Center graphic again. The experiment is to pick one teen at random from the population represented in the charts. Facebook...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_01/02_Exact_Calculation_or_Bound.html",
        "teaser":null},{
        "title": "Fundamental Rules",
        
        "excerpt":
            "Fundamental Rules In 1933, the Russian mathematician Andrey Kolmogorov established the axioms of the modern theory of probability. You will see that the axioms are generalizations of the natural properties of proportions that we have already used in our calculations. We will start this section with formal defnitions of some familiar terms. We will then state the axioms and list some important consequences. Outcome Space and Events $\\bullet$ An outcome space or sample space is the set of all possible outcomes of an experiment. The outcome space could be finite, for example when the experiment is one roll of a...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_01/03_Fundamental_Rules.html",
        "teaser":null},{
        "title": "Exercises",
        
        "excerpt":
            "Exercises 1. In 2017, a Pew Research Center survey asked a random sample of American adults an open-ended question: \"If a current high school student asked you for advice on what sort of career they should pursue, what would you tell them?\" Here adults are defined as people aged 18 or more. The Center's report provides the following summary of the responses. Assume that the percents in the chart were accurate for the US adult population in 2017. a) Read the Note at the bottom of the chart and explain what you think the word NET means in this context....",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_01/04_Exercises.html",
        "teaser":null},{
        "title": "Intersections and Conditioning",
        
        "excerpt":
            "Intersections and Conditioning The main axiom of probability specifies the chance of the union of mutually exclusive events. As you have seen, when events are not mutually exclusive we have to understand their overlap or intersection in order to find the chance of the union. Probabilists and data scientists are often interested in chances of intersections. The chance that we lose all our bets, or that a randomly picked person is at risk for a disease and doesn't have health insurance, are just two examples. So when it comes to intersections, probabilists have shortened even the standard notation of set...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_02/00_Intersections_and_Conditioning.html",
        "teaser":null},{
        "title": "The Chance of an Intersection",
        
        "excerpt":
            "The Chance of an Intersection The intersection of two events is a subset of each of them, so its chance is less than or equal to the chance of each one and hence is at most equal to the minimum of the two chances. $$ P(AB) ~ \\le ~ \\min(P(A), P(B)) $$ But how do we find it exactly? Let's start out with a simple example. Two Cards from a Deck of Three I deal two cards at random without replacement from a deck that contains one red, one blue, and one green card. This means: I pick one of...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_02/01_The_Chance_of_an_Intersection.html",
        "teaser":null},{
        "title": "Symmetry in Simple Random Sampling",
        
        "excerpt":
            "Symmetry in Simple Random Sampling Sampling individuals at random without replacement is one of the most natural ways to collect a random sample from a finite population. It is called simple random sampling and will be studied extensively in this course. But before we get to large populations, we will examine simple random sampling in the context of dealing hands of cards from a deck (or population) of size 52. This will help us see some beautiful symmetries that arise when we sample at random without replacement. Product Rule of Counting We saw earlier that if you deal five cards...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html",
        "teaser":null},{
        "title": "Bayes' Rule",
        
        "excerpt":
            "Bayes' Rule Thus far, we have used the multiplication rule $P(AB) = P(A)P(B \\mid A)$ only in settings where the conditional probability $P(B \\mid A)$ is clear as the proportion of outcomes that are in $B$ among only the outcomes that are in $A$. The general definition of conditional probability, regardless of setting, is just a rearrangement of the multiplication rule. Conditional Probability (Division Rule) Let $A$ and $B$ be two events and let $P(A) &gt; 0$. The conditional probability of $B$ given $A$ is defined as $$ P(B \\mid A) ~ = ~ \\frac{P(AB)}{P(A)} $$ It makes sense to...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_02/03_Bayes_Rule.html",
        "teaser":null},{
        "title": "Use and Interpretation",
        
        "excerpt":
            "Use and Interpretation There are many situations in the law, medicine, and other fields, where Bayes' Rule might help make decisions. Given the evidence, is the defendant guilty or not? Given the test results, does the patient have the disease, or not? But not all medical or legal professionals have taken data science classes. So the calculations are sometimes misinterpreted or done incorrectly or simply not done at all. Here is an example that demonstrates some of the issues that are involved. Harvard Medical School Survey In 1978, Cascella, Schoenberger, and Grayboys asked 60 physicians, students, and house officers at...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_02/04_Use_and_Interpretation.html",
        "teaser":null},{
        "title": "Independence",
        
        "excerpt":
            "Independence Events $A$ and $B$ are independent if the information that one of them occurred does not change the chance of the other. If you don't know whether $A$ has occurred, then the chance of $B$ is just $P(B)$. If you do know that $A$ occurred, then you have to update the chance of $B$ to $P(B \\mid A)$, the conditional chance of $B$ given $A$. The definition of independence says that $A$ and $B$ are independent if $P(B \\mid A) = P(B)$. For example, suppose you roll a die once and see an odd number. What does that tell...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_02/05_Independence.html",
        "teaser":null},{
        "title": "Exercises",
        
        "excerpt":
            "Exercises 1. There are 2,598,960 different poker hands. Suppose I play poker two times so that each time all hands are equally likely regardless of which hand I got the other time. The chance that I get the same hand both times is equal to (pick one and explain): (i) $\\frac{1}{2598960} \\times \\frac{1}{2598960}$ (ii) $\\frac{1}{2598960}$ (iii) Neither (i) nor (ii) 2. A population consists of equal numbers of students in four categories: freshman, sophomore, junior, and senior. a) Suppose there are 8 people in the population, and a simple random sample of 4 people is drawn. What is the chance...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_02/06_Exercises.html",
        "teaser":null},{
        "title": "Random Counts",
        
        "excerpt":
            "Random Counts The number of people who will vote for a Presidential candidate, the number of treated patients who recover, the number of correct predictions made by a sports journalist – all of these are example of counts. Random counts occur commonly in data science. Understanding them not only helps answer questions about the situations in which they arose but also helps us understand more complicated random quantities. In this chapter we will start out with random counts that seem unlikely. We will then develop some general terminology and notation for dealing with random quantities that have numerical values. Our...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_03/00_Random_Counts.html",
        "teaser":null},{
        "title": "Success and Failure",
        
        "excerpt":
            "Success and Failure In experiments that involve drawing at random, it is common to label the draws as \"trials\". For most of this chapter, we will consider experiments in which the result of each trial is in one of a fixed set of categories. For example, in tosses of a coin the categories are usually heads and tails. In cards dealt from a deck, the categories could be the four suits. When we count outcomes in a particular category, the category that is being counted is often called a \"success\". When used in this sense, the word \"success\" does not...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_03/01_Success_and_Failure.html",
        "teaser":null},{
        "title": "Random Variables",
        
        "excerpt":
            "Random Variables Random numerical quantities such as \"the number of heads in ten tosses of a coin\" are called random variables. The terminology and notation of random variables helps reduce the amount of writing involved in phrases like \"the chance that there are no more than 4 heads in ten tosses of a coin.\" Formally, suppose you have an outcome space $\\Omega$. A random variable is a numerical function on $\\Omega$. That is, a random variable is a function whose domain is $\\Omega$ and whose range is the number line. Number of Heads in Three Tosses As our first example,...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_03/02_Random_Variables.html",
        "teaser":null},{
        "title": "The Binomial Distribution",
        
        "excerpt":
            "The Binomial Distribution We have just seen how to find the distribution of the number of heads in three tosses of a coin. In this section we will generalize the method and find the distribution of the number of heads in any fixed number of tosses of any coin, fair or biased. The image of tossing coins (possibly biased) and counting heads is a good way to think about counting successes in repeated independent trials. For example: Counting the number of times the face with two spots appears in 10 rolls of a die is like counting the number of...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_03/03_The_Binomial_Distribution.html",
        "teaser":null},{
        "title": "The Hypergeometric Distribution",
        
        "excerpt":
            "The Hypergeometric Distribution When you are sampling at random from a finite population, it is more natural to draw without replacement than with replacement. In this section, we imagine a population of elements each of which is in one of two categories. The goal is to study the number of sampled elements in one category. We will stick with the probabilists' tradition of calling the two categories \"good\" and \"bad\". You could also call them \"success\" and \"failure,\" in parallel with the previous section. Consider a population of $N$ elements, $G$ of which are good and the remaining $N-G$ are...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_03/04_The_Hypergeometric_Distribution.html",
        "teaser":null},{
        "title": "Examples",
        
        "excerpt":
            "Examples This section consists of an assortment of examples of the use of the binomial and hypergeometric distributions. In each example you will see some of the main problem solving techniques we have developed: Breaking the problem down into smaller pieces Examining the assumptions and hence deciding which distributions can be used Organizing the information to identify the parameters of the distributions Partitioning events into component pieces Using the addition and multiplication rules carefully Advisor Meetings An advisor at a university provides guidance to 10 students. Each student has to meet with her once a month during the school year...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_03/05_Examples.html",
        "teaser":null},{
        "title": "Exercises",
        
        "excerpt":
            "Exercises 1. In a move in the game Monopoly, a die is rolled twice. Let $D_1$ be the number of spots on the first roll, $D_2$ the number of spots on the second roll, and $S = D_1 + D_2$ the total number of spots on the two rolls. a) Find the distribution of $S$. b) Find $P(S &gt; 7)$. c) Find $P(|S - 7| \\le 2)$. 2. A true-false test has 20 questions. a) Dev hasn't studied at all, so he guesses each answer by tossing a coin. Let $R$ be the number of questions that Dev gets right....",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_03/06_Exercises.html",
        "teaser":null},{
        "title": "Infinitely Many Values",
        
        "excerpt":
            "Infinitely Many Values The random variables we have studied thus far have had a finite number of possible values. For example, a random variable that has the binomial $(100, 0.5)$ distribution can be no bigger than 100. Much of data science involves large random samples. If you think of $n$ as a sample size, then natural questions arise about the properties of the sample when $n$ is large. To answer these questions, it helps to think about the sample size $n$ tending to infinity. That usually involves imagining an arbitrarily large set of possible values. This leads naturally to thinking...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_04/00_Infinitely_Many_Values.html",
        "teaser":null},{
        "title": "Cumulative Distribution Function (CDF)",
        
        "excerpt":
            "Cumulative Distribution Function (CDF) There are many ways of specifying distributions. We have sometimes used a table to display the distribution of a random variable $X$. At other times we have written $P(X = k)$ as a formula for each possible value $k$ of $X$. Another useful function that encapsulates all the information about the distribution of $X$ is called the cumulative distribution function of $X$. That's a real mouthful, so it is usually abbreviated to the cdf of $X$. Let's see what the cdf is in an example. Suppose $X$ has the distribution given below. It happens to be...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_04/01_Cumulative_Distribution_Function.html",
        "teaser":null},{
        "title": "Waiting Times",
        
        "excerpt":
            "Waiting Times Suppose you are running a sequence of trials. The waiting time of an event is the number of trials that you run till the event takes place. For example, suppose you roll are rolling a die. The waiting time till you see a six is the number of trials up to and including the trial that produced the first six. The waiting time till you see 10 sixes is the number of trials up to and including the trial that produced the tenth six. In this section we will find the distribution of the waiting time till a...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_04/02_Waiting_Times.html",
        "teaser":null},{
        "title": "Exponential Approximations",
        
        "excerpt":
            "Exponential Approximations Many probabilities are products or powers of fractions. To get a rough sense of the size of such a chance, it is often a good idea to take its logarithm and try to approximate that. This leads to an exponential approximation for the chance. An example will help us see how this works. Bootstrap A bootstrap sample is a sample of size $n$ drawn at random with replacement from an original sample of $n$ individuals. Because the sample is drawn with replacement, some individuals may be drawn more than once and some not at all. Fix an individual...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_04/03_Exponential_Approximations.html",
        "teaser":null},{
        "title": "The Poisson Distribution",
        
        "excerpt":
            "The Poisson Distribution Data scientists use probability distributions as models for how their data are generated. In this context a model is a set of assumptions involving probabilities. Almost invariably, models are simplified representations of complex real scenarios. The Poisson distribution is sometimes used to model the number of times a rare event occurs. It is named after its originator, the French mathematician, scientist, and engineer Siméon Denis Poisson. The parameter of the Poisson distribution is a positive number which we will call $\\mu$. A random variable $X$ has the Poisson distribution with parameter $\\mu$ if $$ P(X = k)...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_04/04_The_Poisson_Distribution.html",
        "teaser":null},{
        "title": "Exercises",
        
        "excerpt":
            "Exercises 1. At rush hour, passengers in a subway station come down an escalator to the platforms and choose either the Eastbound or the Westbound platform. Assume that each passenger chooses the Eastbound platform with chance 0.8 independently of all other passengers. Suppose you start watching the escalator at the start of rush hour. a) Find the chance that the first passenger to choose the Westbound platform is the fifth passenger that you see. b) Find the chance that more than 15 passengers choose the Eastbound platform before the first one who chooses the Westbound platform. 2. A random variable...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_04/05_Exercises.html",
        "teaser":null},{
        "title": "Expectation",
        
        "excerpt":
            "Expectation The distribution of a random variable $X$ contains all the information you need to find probabilities of events determined by $X$. For example, to find the chance that $X$ is greater than 20, you can identify all the possible values of $X$ that are greater than 20 and then add up all their chances. Sometimes, we don't need all this information. We might just want to know roughly how big $X$ is. For this we need a rough sense of where the distribution of $X$ is situated on the number line. In this chapter we will study a quantity...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_05/00_Expectation.html",
        "teaser":null},{
        "title": "Definition",
        
        "excerpt":
            "Definition The expectation of a random variable $X$, denoted $E(X)$, is the average of the possible values of $X$ weighted by their probabilities: $$ E(X) = \\sum_{\\text{all }x} xP(X=x) $$ Technical Note: If $X$ has finitely many possible values, the sums above are always well defined and finite. If $X$ can have countably many values (that is, values indexed by 1, 2, 3, $\\ldots$), then more care is needed to make sure that the formulas result in a well defined number. You don't have to worry about that in this course. For example, suppose $X$ has the following distribution table....",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_05/01_Definition.html",
        "teaser":null},{
        "title": "Functions of Random Variables",
        
        "excerpt":
            "Functions of Random Variables When we work with random variables, we often want to consider functions of them. For example, if $X$ is a random length in inches then $Y = 2.54X$ is the length in centimeters, and $W = \\vert X - 12 \\vert $ measures how far $X$ is from 12 inches. If we know the distribution of $X$ we can easily find the expectation of any function of $X$, as in the example below. Let $X$ have the uniform distribution on $\\{ -1, 0, 1 \\}$, and let $Y = X^2$. Let's find $E(Y)$. Here is a...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_05/02_Functions_of_Random_Variables.html",
        "teaser":null},{
        "title": "Method of Indicators",
        
        "excerpt":
            "Method of Indicators The additivity property of expectation says that for any two random variables $X$ and $Y$ defined on the same space, $$ E(X+Y) ~ = ~ E(X) + E(Y) $$ regardless of the joint distribution of $X$ and $Y$. In particular, expectation is additive regardless of the dependence or independence of the two random variables being added. Remember that throughout this course, you can assume that there are no problems with the existence of expectations of random variables that have infinitely many values. In more advanced courses you will have to be careful about infinities in the statement...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_05/03_Method_of_Indicators.html",
        "teaser":null},{
        "title": "Unbiased Estimators",
        
        "excerpt":
            "Unbiased Estimators Data scientists often use information in random samples to estimate unknown numercial quantities. For example, they might estimate the unknown average income in a large population by using incomes in a random sample drawn from the population. In this section we will examine one criterion for a good estimate. First let's note a straightforward but extremely handy property of expectation. Preliminary: Linear Function Rule Let $X$ be a random variable and let $Y = aX + b$. Then $Y$ is a linear function of $X$. By our method for finding the expectation of a function of a random...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_05/04_Unbiased_Estimators.html",
        "teaser":null},{
        "title": "Conditional Expectation",
        
        "excerpt":
            "Conditional Expectation As our course begins to move towards estimation and prediction, it is a good idea to formalize some ways of quantifying how one variable is related to another. We are going to want to use information given about one variable to predict the unknown value of another. In the language of random variables, \"information given about one variable\" is conditioning, of course. You have been calculating conditional probabilities and conditional distributions for some time now. We will start this section with a formal definition of a conditional distribution, though you can continue to work with your intuitive sense...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_05/05_Conditional_Expectation.html",
        "teaser":null},{
        "title": "Expectation by Conditioning",
        
        "excerpt":
            "Expectation by Conditioning Expectation is a long-run average, so properties of expectation are properties of averages. The method of calculating expectation by conditioning, developed in the previous section, is equivalent to the calculation of the average of a group based on information about subgroups. As an example, suppose a class of 60 students is split into two sections of sizes 40 and 20. After the midterm, the average scores in the two sections are recorded in a table. Section A B Average 80 70 Size 40 20 Then the class average can be calculated as $$ \\text{class average} ~ =...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_05/06_Expectation_by_Conditioning.html",
        "teaser":null},{
        "title": "Exercises",
        
        "excerpt":
            "Exercises 1. Let $X$ have the distribution displayed in the table below. $~~~~~~~~~~~~~~~~x$ $-2$ $-1$ $0$ $1$ $P(X=x)$ $0.2$ $0.25$ $0.35$ $0.2$ Find a) $E(X)$ b) $E(X-1)$ c) $E(\\vert X - 1 \\vert)$ d) $E((X-1)^2)$ 2. A true/false test consists of 25 questions. A student knows the correct answer to 10 of the questions. She guesses each of the other answers independently based on the toss of a coin. a) Find the expectation of the number of correct answers. b) Find the chance that the student gets more than 20 questions right. 3. A box contains four blank index cards...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_05/07_Exercises.html",
        "teaser":null},{
        "title": "Measuring Variability",
        
        "excerpt":
            "Measuring Variability Expectation is the center of gravity of a probability histogram, and is thus a measure of where the histogram is located on the number line. But histograms of very different distributions can have the same expectation. In the example below, both Distribution 1 and Distribution 2 balance at 3.5. The probabilities in Distribution 2 are more concentrated around the center of the distribution. So it seems less spread out than Distribution 1. In this chapter we will quantify the spread or variability in a distribution. Once we have defined a measure of spread and examined how to calculate...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_06/00_Measuring_Variability.html",
        "teaser":null},{
        "title": "Variance and Standard_Deviation",
        
        "excerpt":
            "Variance and Standard Deviation Let $X$ be a random variable and let $\\mu_X = E(X)$. The deviation from expected value, informally called the deviation from average or just deviation for short, is defined as the difference $$ D ~ = ~ X - \\mu_X $$ Thus $D$ is the amount by which $X$ exceeds its expectation $\\mu_X$. Note that $D$ is negative when $X &lt; \\mu_X$. The goal of this section is to quantify the rough size of $D$. One natural approach is to find $E(D)$, but that results in $$ E(D) ~ = ~ E(X - \\mu_X) ~ =...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_06/01_Variance_and_Standard_Deviation.html",
        "teaser":null},{
        "title": "Simplifying the Calculation",
        
        "excerpt":
            "Simplifying the Calculation To calculate the variance, we have had to find each deviation, square it, and then find the weighted average of of the squares. It's worth seeing if we can reduce this work. Linear Transformations When we change units, we usually multiply the variable by a constant. For example if $X$ is a length in inches then $Y = 2.54X$ is the same length in centimeters. If $X$ is a temperature in degrees Celsius then $Y = (9/5)X + 32$ is the same temperature in degrees Fahrenheit. Both of these are linear transformations of $X$. We will now...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_06/02_Simplifying_the_Calculation.html",
        "teaser":null},{
        "title": "Markov's Inequality",
        
        "excerpt":
            "Markov's Inequality To understand the accuracy of estimates, it helps to start by examining the chance that a random variable is far from its mean. In this section we will see what we can say about how far a non-negative random variable can be from its mean, using only the mean and not the SD. Tail Probabilities Let $X$ be a non-negative random variables. That means all the possible values of $X$ are non-negative. Almost all the random variables you have encountered in this course so far have been non-negative. Fix $c &gt; 0$ and consider the right hand tail...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_06/03_Markovs_Inequality.html",
        "teaser":null},{
        "title": "Chebyshev's Inequality",
        
        "excerpt":
            "Chebyshev's Inequality Markov's inequality gives us upper bounds on the tail probabilities of a non-negative random variable, based only on the expectation. It seems reasonable to think we might be able to do better if we also used the SD of the distribution. Let $X$ be any random variable (not necessarily non-negative) and let $c$ be any positive number. What can we say about the chance that $X$ is at least $c$ units away from its mean? Let $\\mu = E(X)$ and $\\sigma = SD(X)$. Data scientists often use $\\sigma$ for SD because $\\sigma$ is the Greek for s. We...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_06/04_Chebyshevs_Inequality.html",
        "teaser":null},{
        "title": "Exercises",
        
        "excerpt":
            "Exercises 1. Let the distribution of $X$ be $~~~~~~~~~~~ x$ 1 2 3 $P(X=x)$ $0.2$ $0.5$ $0.3$ Find $E(X)$ and $Var(X)$. 2. A person is picked at random from a population. Let $Y$ be the year in which the person was born, and suppose $E(Y) = 1997$ and $SD(Y) = 2$. Define the person's age in 2019 to be $X = 2019 - Y$. Find $E(X)$ and $SD(X)$. 3. In each part, construct the distribution of a random variable $X$ that satisfies the conditions given. A great way to construct examples is to keep them as simple as possible: random...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_06/05_Exercises.html",
        "teaser":null},{
        "title": "The Variance of a Sum",
        
        "excerpt":
            "    The Variance of a Sum            Additivity is the most important property of expectation. It has helped us find numerous expectations that would have been hard to find by other means.  It is natural to ask whether variance also has an additivity property. In this chapter we will explore that question and use what we discover to find the SDs of many different random variables.  We will also use properties of variance to illuminate some properties of large random samples, including the law of averages.           ",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_07/00_The_Variance_of_a_Sum.html",
        "teaser":null},{
        "title": "Sums of Independent Random Variables",
        
        "excerpt":
            "Sums of Independent Random Variables For two random variables $X$ and $Y$, the additivity property $E(X+Y) = E(X) + E(Y)$ is true regardless of the dependence or independence of $X$ and $Y$. But variance doesn't behave quite like this. Let's look at an example. Two Rolls of a Die Suppose a die is rolled two times. Let $D_1$ and $D_2$ be the numbers on Rolls 1 and 2. Then $D_1$ and $D_2$ have the same distribution: both are uniform on $1, 2, 3, 4, 5, 6$. So $E(D_1) = E(D_2) = 3.5$. Define two sums as follows: $V = D_1...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_07/01_Sums_of_Independent_Random_Variables.html",
        "teaser":null},{
        "title": "Sampling Without Replacement",
        
        "excerpt":
            "Sampling Without Replacement The draws in a simple random sample aren't independent of each other. This makes calculating variances a little less straightforward than in the case of draws with replacement. In this section we will find the variance of a random variable that has a hypergeometric distribution. Then we will use the variance to examine the accuracy of polls. As a preliminary, let's do some calculations involving indicator random variables. Squares and Products of Indicators Let $I_A$ be the indicator of the event $A$. Then the distribution of $I_A$ is given by value $0$ $1$ probability $1-P(A)$ $P(A)$ We...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_07/02_Sampling_Without_Replacement.html",
        "teaser":null},{
        "title": "The Law of Averages",
        
        "excerpt":
            "The Law of Averages Informally, the law of averages is the familiar statement that if you toss a coin many times you get about half heads and half tails. The main reason for studying the law of averages is to begin to understand why large random samples are the basis for inference in data science. In this section we will take a close look at the informal statement of the law and try to make it more precise. In the process, we will confirm some intuition about probabilities and also come across a fact that may be surprising. The Sample...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_07/03_The_Law_of_Averages.html",
        "teaser":null},{
        "title": "Exercises",
        
        "excerpt":
            "Exercises 1. Let $X$ and $Y$ be independent random variables such that $E(X) = 10$, $SD(X) = 3$ $E(Y) = -8$, $SD(Y) = 4$ Let $V = 5X - 2Y + 9$. Find $E(V)$, $Var(V)$, and $SD(V)$. 2. A multiple choice test has 60 questions. Each question has three possible answers, one of which is correct. Let $R$ be the number of correct answers a student gets by guessing all the answers independently at random. Find $E(R)$ and $SD(R)$. 3. In roulette, a bet on a \"split\" pays 17 to 1 and there are two chances in 38 to win....",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_07/04_Exercises.html",
        "teaser":null},{
        "title": "The Central Limit Theorem",
        
        "excerpt":
            "Central Limit Theorem It is important for data scientists to understand random sample averages, as those statistics are frequently used for estimating parameters. We know the expectation and SD of the mean of an i.i.d. sample, and we have observed that the distribution of the sample mean gets increasingly concentrated around the underlying population mean as the sample size gets larger. What you might also have noticed is that in many of our examples, the distribution of the sample mean looks bell shaped. The reason is a fundamental theorem of probability and statistical inference: the Central Limit Theorem. This chapter...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_08/00_Central_Limit_Theorem.html",
        "teaser":null},{
        "title": "Distribution of a Sample Sum",
        
        "excerpt":
            "The Distribution of a Sample Sum Let $X_1, X_2, \\ldots, X_n$ be i.i.d. with mean $\\mu$ and SD $\\sigma$, and let $S_n = X_1 + X_2 + \\cdots + X_n$ be the sample sum. We know that $$ E(S_n) ~ = ~ n\\mu ~~~~~~~~~~~~~~ SD(S_n) ~ = ~ \\sqrt{n}\\sigma $$ This section is about the shape of the distribution of $S_n$. In principle, we know how to find the distribution of $S_n$ by using the common distribution of the $X_i$s. For example, if $n = 2$, $$ \\begin{align*} P(S_2 = s) ~ &amp;= ~ \\sum_k P(X_1 = k, X_2 =...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_08/01_Distribution_of_a_Sample_Sum.html",
        "teaser":null},{
        "title": "Standard Normal Curve",
        
        "excerpt":
            "Standard Normal Curve The normal or Gaussian curves are a family of bell-shaped curves named for the German mathematician and scientist Carl Friedrich Gauss. Here are few members of the family. You can see that there really is only one bell shape; the differences between the curves are due to where they are centered and how wide the bells are. In other words, the differences are due to the scales on which the variables are being measured. In essence, therefore, there is only one normal curve – all the others can be derived by changing the origin and the units...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_08/02_Standard_Normal_Curve.html",
        "teaser":null},{
        "title": "Normal Approximation",
        
        "excerpt":
            "Normal Approximation In this section we will use the Central Limit Theorem and the standard normal curve to approximate probabilities. To get started, note that whether a histogram looks bell-shaped or whether it is skewed in one direction or another doesn't depend on the units in which the variable is measured. So data scientists use a special scale that doesn't depend on the units of measurement and can be used for measuring any random quantity. This scale is called the standard units scale. Standard Units Let $X$ be any random variable with $E(X) = \\mu$ and $SD(X) = \\sigma$. We...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_08/03_Normal_Approximation.html",
        "teaser":null},{
        "title": "How Large is Large",
        
        "excerpt":
            "How Large is \"Large\"? Let $X_1, X_2, \\ldots, X_n$ be i.i.d. with mean $\\mu$ and SD $\\sigma$, and let $S_n = X_1 + X_2 + \\cdots + X_n$. The Central Limit Theorem says that no matter what the distribution of $X_1$, after some large enough $n$ the distribution of $S_n$ looks roughly normal. This raises the question of how large is \"large enough\". We have seen in examples that the answer depends on the distribution of $X_1$. If the distribution of $X_1$ is smooth and symmetric, the distribution of the sample sum can start looking normal even when the sample...",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/Chapter_08/04_How_Large_is_Large.html",
        "teaser":null},{
        "title": "Authors and License",
        
        "excerpt":
            "    STAT 88  Theory Meets Data   By Ani Adhikari  This is the textbook for the Probability and Mathematical Statistics in Data Science class at UC Berkeley.  The contents of this book are licensed for free consumption under the following license: Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)     MathJax.Hub.Config({     tex2jax: {       inlineMath: [['$','$']],       processEscapes: true     }\\           ",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/intro.html",
        "teaser":null},{
        "title": "Authors and License",
        
        "excerpt":
            "STAT 88   Theory Meets Data   By Ani Adhikari   This is the textbook for the Probability and Mathematical Statistics in Data Science class at UC Berkeley.   The contents of this book are licensed for free consumption under the following license:  Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)    ",
        "categories": [],
        "tags": [],
        "url": "http://0.0.0.0:4000/textbook/notebooks/intro.html",
        "teaser":null},]
</script>
            </div>
            <nav class="c-page__nav">
  

  
</nav>

            <footer>
  <p class="footer">This page was created by <a href="https://github.com/jupyter/jupyter-book/graphs/contributors">The Jupyter Book Community</a></p>
</footer>

        </div>
      </main>
    </div>
  </body>
</html>
